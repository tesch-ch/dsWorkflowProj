{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e307d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Third-party imports\n",
    "import torch # TODO: might remove, transformers sometimes throws warnings?\n",
    "from transformers import (AutoTokenizer,\n",
    "                          AutoModelForSequenceClassification,\n",
    "                          AutoModelForTokenClassification,\n",
    "                          pipeline)\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Local imports\n",
    "import misc\n",
    "\n",
    "\n",
    "# Connect to MongoDB\n",
    "# MONGODB_HOST = 'localhost'\n",
    "MONGODB_HOST = 'mongodb-service' # must fit k8s service name\n",
    "MONGODB_PORT = 27017\n",
    "print(\"Connect to MongoDB.\")\n",
    "client = MongoClient(MONGODB_HOST, MONGODB_PORT)\n",
    "db = client['news']\n",
    "collection = db['articles']\n",
    "\n",
    "# Count number of documents in collection where 'entities' field is missing\n",
    "# (i.e. where nlp has not been performed yet) and where the 'authors' field is\n",
    "# not empty (i.e. \"proper\" articles, not e.g. weather reports or landing pages)\n",
    "query = {'entities': {'$exists': False}, 'authors': {'$ne': []}}\n",
    "# query = {'authors': {'$ne': []},}\n",
    "count = collection.count_documents(query)\n",
    "print(f'Number of documents to process: {count}')\n",
    "\n",
    "# Exit if no documents to process\n",
    "if count == 0:\n",
    "    print(\"No documents to process. Exiting.\")\n",
    "    sys.exit(0)\n",
    "\n",
    "# Init classifier model for inference on article text\n",
    "# https://huggingface.co/Softechlb/articles_classification\n",
    "CLF_MODEL_NAME = \"Softechlb/articles_classification\"\n",
    "print(\"Init classifier model.\")\n",
    "clf_tokenizer = AutoTokenizer.from_pretrained(CLF_MODEL_NAME)\n",
    "clf_model = AutoModelForSequenceClassification.from_pretrained(CLF_MODEL_NAME)\n",
    "\n",
    "# Init NER model for inference on article title\n",
    "# https://huggingface.co/dslim/bert-base-NER\n",
    "NER_MODEL_NAME = \"dslim/bert-base-NER\"\n",
    "print(\"Init NER model.\")\n",
    "ner_tokenizer = AutoTokenizer.from_pretrained(NER_MODEL_NAME)\n",
    "ner_model = AutoModelForTokenClassification.from_pretrained(NER_MODEL_NAME)\n",
    "ner_pipeline = pipeline(\"ner\", model=ner_model, tokenizer=ner_tokenizer,\n",
    "                        aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55482866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over documents in collection\n",
    "progress = misc.ProgressLog(count)\n",
    "error_count = 0\n",
    "print(\"Start processing documents.\")\n",
    "start_time = time.time()\n",
    "for document in collection.find(query):\n",
    "    \n",
    "    try:\n",
    "        # Perform NER on article title\n",
    "        (entities, entities_all) = misc.perform_ner(document['title'], ner_pipeline)\n",
    "        \n",
    "        # Perform classification on article text\n",
    "        (label, labels_all) = misc.perform_clf(document['text'], clf_tokenizer, clf_model)\n",
    "\n",
    "        # Update document in collection\n",
    "        document['entities'] = entities\n",
    "        document['entities_verbose'] = entities_all\n",
    "        document['category'] = label\n",
    "        document['category_verbose'] = labels_all\n",
    "        collection.update_one({'_id': document['_id']}, {'$set': document})\n",
    "\n",
    "    except Exception as e:\n",
    "        error_count += 1\n",
    "        print(f\"\\nError no. {error_count} while \"\n",
    "              f\"processing document {document['_id']}:\\n{e}\\n\\n\")\n",
    "\n",
    "    # Print progress\n",
    "    progress.increase(suffix=f\"{document['_id']}: {document['title']}\")\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(f\"\\n\\nProcessing {count} documents took {duration / 60:.0f} min.\\n\"\n",
    "      f\"Average time per document: {duration / count:.2f} s.\")\n",
    "\n",
    "# Close connection to mongo db\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
